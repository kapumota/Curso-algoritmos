{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef6c4035-5534-4e30-922f-202bda0c6b42",
   "metadata": {},
   "source": [
    "# Notación asintótica\n",
    "\n",
    "Dadas las expresiones para mejor, promedio y peor caso, necesitamos representar formalmente las **cotas superior** y **cotas inferior**. Para ello, usamos cierta notación especial, que es el tema del siguiente cuaderno. Asumamos que el algoritmo se expresa como una función $f(n)$.\n",
    "\n",
    "\n",
    "## 1.1 Notación Big-O\n",
    "\n",
    "Esta notación proporciona la **cota superior ajustada** (tight upper bound) de la función dada. Normalmente se representa como $f(n) = O(g(n))$. Esto significa que, para valores grandes de $n$, la tasa de crecimiento de $f(n)$ es **como máximo** $g(n)$.  \n",
    "Por ejemplo, si $f(n) = n^4 + 100n^2 + 10n + 50$, entonces $g(n)$ es $O(n^4)$.\n",
    "\n",
    "La definición formal es:  \n",
    "$$\n",
    "O(g(n)) = \\{\\,f(n): \\exists \\, c, n_0 > 0 \\;\\text{tal que}\\; 0 \\le f(n) \\le c\\,g(n) \\;\\;\\text{para todo}\\; n \\ge n_0\\}.\n",
    "$$\n",
    "\n",
    "En términos sencillos, queremos encontrar la **tasa de crecimiento más grande** que **domina** a $f(n)$ cuando $n$ tiende a infinito. Ignoramos las constantes y los términos de menor orden.\n",
    "\n",
    "Hay varios **ejemplos** sencillos:\n",
    "\n",
    "- $3n + 8$ es $O(n)$.  \n",
    "- $n^2 + 1$ es $O(n^2)$.  \n",
    "- $n^4 + 100n^2 + 50$ es $O(n^4)$.  \n",
    "- $2n^3 - 2n^2$ es $O(n^3)$.  \n",
    "- $4^{10}$ (constante) es $O(1)$.\n",
    "\n",
    "Generalmente descartamos valores más bajos de $n$. Esto significa que la tasa de crecimiento en valores más bajos de $n$ no es importante. por ejemplo $n_0$  es el punto a partir del cual necesitamos considerar la tasa de crecimiento para un algoritmo dado Por debajo de $n_0$, la tasa de crecimiento podría ser diferente. $n_0$ se llama umbral para la función dada.\n",
    "\n",
    "\n",
    "$O(g(n))$ es el conjunto de funciones con un orden de crecimiento menor o igual al de $g(n)$. Por ejemplo, $O(n^2)$ incluye $O(1)$, $O(n)$, $O(n \\log n)$, etc.\n",
    "\n",
    "### 1.2 ¿No hay unicidad?\n",
    "\n",
    "No hay un conjunto único de valores para $n_0$ y $c$ al probar los límites asintóticos. Consideremos, por ejemplo, $100n + 5 = O(n)$. Para esta función, hay múltiples valores posibles de $n_0$ y $c$.\n",
    "\n",
    "- **Solución 1:**   $100n + 5 \\leq 100n + n = 101n \\leq 101n$, para todo $n \\geq 5$, $n_0 = 5$ y $c = 101$ es una solución.\n",
    "\n",
    "- **Solución 2:**   $100n + 5 \\leq 100n + 5n = 105n \\leq 105n$, para todo $n \\geq 1$, $n_0 = 1$ y $c = 105$ también es una solución.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.3 Notación Big Omega ($\\Omega$)\n",
    "\n",
    "Similar a Big-O, esta notación proporciona la **cota inferior ajustada** (tight lower bound) de la función, y se representa como $f(n) = \\Omega(g(n))$. Esto significa que, para valores grandes de $n$, la tasa de crecimiento de $f(n)$ es **como mínimo** $g(n)$.  \n",
    "La definición formal es:  \n",
    "\n",
    "$$\n",
    "\\Omega(g(n)) = \\{\\,f(n): \\exists \\, c, n_0 > 0 \\;\\text{tal que}\\; 0 \\le c\\,g(n) \\le f(n) \\;\\;\\text{para todo}\\; n \\ge n_0\\}.\n",
    "$$\n",
    "\n",
    "Por ejemplo, si $f(n) = 100n^2 + 10n + 50$, su cota inferior ajustada es $\\Omega(n^2)$.\n",
    "\n",
    "**Ejemplos:**\n",
    "\n",
    "**Ejemplo 1:** Encontrar la cota inferior para $f(n) = 5n^2$.\n",
    "\n",
    "**Solución:**  \n",
    "$\\exists c, n_0$ tal que:  \n",
    "$0 \\leq cn^2 \\leq 5n^2 \\Rightarrow c = 1$ y $n_0 = 1$.  \n",
    "Por lo tanto, $5n^2 = \\Omega(n^2)$ con $c = 1$ y $n_0 = 1$.\n",
    "\n",
    "\n",
    "**Ejemplo 2:** Probar que $f(n) = 100n + 5 \\neq \\Omega(n^2)$.\n",
    "\n",
    "**Solución:**  \n",
    "$\\exists c, n_0$ tal que:  \n",
    "$0 \\leq cn^2 \\leq 100n + 5$.  \n",
    "$100n + 5 \\leq 100n + 5n \\ (\\forall n \\geq 1)\\ = 105n$.  \n",
    "$cn^2 \\leq 105n \\Rightarrow n(cn - 105) \\leq 0$.  \n",
    "\n",
    "Dado que $n$ es positivo $\\Rightarrow cn - 105 \\leq 0$.  \n",
    "$\\Rightarrow$ Contradicción: $n$ no puede ser menor que una constante.\n",
    "\n",
    "\n",
    "**Ejemplo 3:** :$2n = \\Omega(n), \\quad n^3 = \\Omega(n^3), \\quad \\log n = \\Omega(\\log n)$.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.4 Notación Big-Theta ($\\Theta$)\n",
    "\n",
    "Esta notación decide si las cotas superior (**O**) e inferior (**$\\Omega$**) de una función (algoritmo) son la **misma**. Es decir, si tanto la cota superior como la inferior tienen el **mismo orden** de crecimiento, entonces decimos que la función se encuentra en $\\Theta(g(n))$.  \n",
    "\n",
    "La definición formal:  \n",
    "\n",
    "$$\n",
    "\\Theta(g(n)) = \\{\\,f(n) : \\exists\\, c_1, c_2, n_0 > 0 \\;\\text{tal que}\\; 0 \\le c_1 \\, g(n) \\le f(n) \\le c_2 \\, g(n) \\;\\;\\text{para todo}\\; n \\ge n_0\\}.\n",
    "$$\n",
    "$g(n)$ es una cota asintótica ajustada para $f(n)$. $\\Theta(g(n))$ es el conjunto de funciones con el mismo orden de crecimiento que $g(n)$.\n",
    "\n",
    "Por ejemplo, si $f(n) = 10n + n$, es $O(n)$ y también $\\Omega(n)$. Por lo tanto, $f(n) = \\Theta(n)$.\n",
    "\n",
    "\n",
    "En este caso, las tasas de crecimiento en el mejor caso y en el peor caso son las mismas. Como resultado, el caso promedio también será el mismo. Para una función dada (algoritmo), si las tasas de crecimiento (cotas) para los casos $O$ y $\\Omega$ no son las mismas, entonces la tasa de crecimiento para el caso $\\Theta$ puede no ser la misma. En este caso, necesitamos considerar todos los posibles tiempos de ejecución y tomar el promedio de estos.\n",
    "\n",
    "\n",
    "### **Ejemplos**\n",
    "\n",
    "**Ejemplo 1:** Encontrar la cota $\\Theta$ para $f(n) = \\frac{n^2}{2} - \\frac{n}{2}$.  \n",
    "\n",
    "**Solución:**  \n",
    "\n",
    "$$\n",
    "\\frac{n^2}{5} \\leq \\frac{n^2}{2} - \\frac{n}{2} \\leq n^2, \\quad \\text{para todo } n \\geq 1\n",
    "$$  \n",
    "\n",
    "Por lo tanto:  \n",
    "\n",
    "$$\n",
    "\\frac{n^2}{5} = \\Theta(n^2) \\text{ con } c_1 = \\frac{1}{5}, c_2 = 1 \\text{ y } n_0 = 1\n",
    "$$\n",
    "\n",
    "\n",
    "**Ejemplo 2:** Probar que $f(n) \\neq \\Theta(n^2)$.\n",
    "\n",
    "**Solución:**  \n",
    "$$\n",
    "c_1n^2 \\leq n \\leq c_2n^2 \\text{ solo se cumple para: } n \\leq \\frac{1}{c_1}\n",
    "$$\n",
    "\n",
    "Por lo tanto:  \n",
    "$$\n",
    "n \\notin \\Theta(n^2)\n",
    "$$\n",
    "\n",
    "\n",
    "**Ejemplo 3:** Probar que $6n^3 \\neq \\Theta(n^2)$.\n",
    "\n",
    "**Solución:**  \n",
    "$$\n",
    "c_1n^2 \\leq 6n^3 \\leq c_2n^2 \\text{ solo se cumple para: } n \\leq \\frac{c_2}{6}\n",
    "$$  \n",
    "Por lo tanto:  \n",
    "$$\n",
    "6n^3 \\neq \\Theta(n^2)\n",
    "$$\n",
    "\n",
    "\n",
    "**Ejemplo 4:** Probar que $$n \\neq \\Theta(\\log n)$$.\n",
    "\n",
    "**Solución:**  \n",
    "$$\n",
    "c_1\\log n \\leq n \\leq c_2\\log n \\Rightarrow c_2 \\geq \\frac{n}{\\log n}, \\forall n \\geq n_0\n",
    "$$  \n",
    "\n",
    "**Imposible.**\n",
    "\n",
    "---\n",
    "\n",
    "**Notas importantes:**  \n",
    "\n",
    "Para el análisis (mejor caso, peor caso y promedio), tratamos de dar la cota superior ($O$) y la cota inferior ($\\Omega$) junto con el tiempo de ejecución promedio ($\\Theta$).\n",
    "\n",
    "A partir de los ejemplos anteriores, también debe quedar claro que, para una función (algoritmo) dada, obtener la cota superior ($O$) y la cota inferior ($\\Omega$) y el tiempo de ejecución promedio ($\\Theta$) puede no ser siempre factible. Por ejemplo, si estamos discutiendo el mejor caso de un algoritmo, tratamos de dar la cota superior ($O$) y el tiempo de ejecución promedio ($\\Theta$).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02103abd-eb4d-4a94-965f-1520a24764c3",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "#### **Pregunta 1**\n",
    "\n",
    "##### **Algoritmo para discutir (pseudo código)**\n",
    "\n",
    "```\n",
    "algorithm compute_array_stuff(a)\n",
    "# a es un arreglo de tamaño n\n",
    "for k = 1 to n:\n",
    "    if a[k] is prime:\n",
    "        return 0\n",
    "\n",
    "sum = 0\n",
    "for i = 1 to n:\n",
    "    for j = i+1 to n:\n",
    "        sum = sum + a[i] * a[j]\n",
    "```\n",
    "\n",
    "\n",
    "##### **Afirmaciones (seleccionar solo las correctas, sin elegir las incorrectas)**\n",
    "\n",
    "1. Para cada n, en el mejor caso, el algoritmo termina tras un número constante de pasos.\n",
    "   Esto ocurre específicamente si el primer elemento del arreglo (posición 1) es un número primo.\n",
    "\n",
    "2. Para cada n, el algoritmo se ejecuta en tiempo lineal en n en el peor caso.\n",
    "\n",
    "3. El peor caso se alcanza cuando el arreglo está compuesto solo por números compuestos (no primos).\n",
    "\n",
    "4. La complejidad en el peor caso del algoritmo está acotada superiormente por $O(n^3)$.\n",
    "\n",
    "5. La complejidad en el peor caso del algoritmo está acotada inferiormente por $\\Omega(n)$.\n",
    "\n",
    "6. La complejidad en el peor caso del algoritmo es $\\Theta(n^2)$.\n",
    "\n",
    "\n",
    "\n",
    "#### **Pregunta 2**\n",
    "\n",
    "El **Algoritmo X**, programado por un “programador experto”, se ejecuta en tiempo  \n",
    "\n",
    "$$\n",
    "2.5\\,n^4 + 3\\,n^3 + 1.4\\,n + 2\n",
    "$$  \n",
    "para entradas de tamaño $n$ en el peor caso.  \n",
    "\n",
    "Otro **algoritmo Y**, programado por un “novato” para el mismo problema, se ejecuta en tiempo  \n",
    "\n",
    "$$\n",
    "2000\\,n + 10000\n",
    "$$  \n",
    "para entradas de tamaño $n$ en el peor caso.\n",
    "\n",
    "Selecciona las respuestas correctas:\n",
    "\n",
    "1. Para entradas de tamaño $n=2$, **X** es mucho más rápido que **Y**.\n",
    "2. El algoritmo **X** será mucho más rápido que **Y** para **todas** las entradas.\n",
    "3. **X** se ejecuta en tiempo $\\Theta(n^4)$.\n",
    "4. **Y** se ejecuta en tiempo $O(n^2)$.\n",
    "5. **Y** es asintóticamente más rápido que **X**.\n",
    "6. Es posible que para alguna entrada de tamaño 100, el algoritmo **X** sea más rápido que **Y**.\n",
    "\n",
    "\n",
    "#### **Pregunta 3**\n",
    "\n",
    "Supón que un algoritmo se ejecuta en tiempo  \n",
    "\n",
    "$$\n",
    "1.5 \\times 2^n + 1.2 \\times n^2\n",
    "$$  \n",
    "en el peor caso. Escoge la respuesta correcta de la siguiente lista:\n",
    "\n",
    "1. Su tiempo de ejecución puede expresarse como $O(3^n)$.\n",
    "2. Dado que las constantes se ignoran en el tiempo asintótico, podemos escribir el tiempo de ejecución como $\\Theta(2^{2n})$.\n",
    "3. El término $1.2 \\times n^2$ domina a $2^n$. Por tanto, la complejidad asintótica del algoritmo es $O(n^2)$.\n",
    "4. No es posible que un algoritmo programado tenga tiempos de ejecución como $2^n$.\n",
    "\n",
    "\n",
    "#### **Pregunta 4**\n",
    "\n",
    "Supón que un algoritmo se ejecuta en tiempo  \n",
    "$$\n",
    "200 \\,\\log_2(n) + 250\n",
    "$$  \n",
    "en el peor caso, dependiendo del tamaño de entrada $n$. ¿Cuáles de las siguientes opciones son correctas?\n",
    "\n",
    "1. El tiempo de ejecución es $\\Theta(\\log_{10}(n))$, dado que $\\log_{10}(n) = \\frac{\\log_2(n)}{\\log_2(10)}$, y la constante $\\frac{1}{\\log_2(10)}$ no afecta la notación asintótica.\n",
    "2. Es imposible que un algoritmo tenga tiempo de ejecución más pequeño que el tamaño de la entrada.\n",
    "3. El tiempo de ejecución del algoritmo es $O(n)$.\n",
    "\n",
    "\n",
    "#### **Pregunta 5**\n",
    "\n",
    "Considera un algoritmo que, dado un número $n$, imprime todos los pares $(i,j)$ tales que $1 \\le i < j \\le n$.  \n",
    "\n",
    "1. Escribe el pseudo código de dicho algoritmo.  \n",
    "2. Determina su complejidad asintótica y justifica tu respuesta.\n",
    "\n",
    "#### **Pregunta 6**\n",
    "\n",
    "Un algoritmo recibe como entrada un arreglo de $n$ elementos. Primero revisa si alguno de los elementos es negativo (si encuentra uno, termina de inmediato). Si no encuentra ninguno, luego realiza un bucle doble para procesar cada par de elementos.  \n",
    "\n",
    "- Describe en qué situaciones se alcanza el mejor caso y en cuáles el peor caso.  \n",
    "- Determina la complejidad en ambos escenarios.\n",
    "\n",
    "#### **Ejercicio 7**\n",
    "Se tiene un algoritmo que suma recursivamente la mitad de los elementos de un arreglo en cada llamada, hasta que queda un solo elemento.  \n",
    "\n",
    "1. Escribe la relación de recurrencia para el tiempo de ejecución $T(n)$.  \n",
    "2. Resuélvela usando la metodología que prefieras (árbol de recurrencia, método maestro, sustitución, etc.) y da la complejidad resultante.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5444ea7b-ee54-4bfe-a3f7-3a041662db1a",
   "metadata": {},
   "source": [
    "## Respuestas\n",
    "\n",
    "#### **Pregunta 1**\n",
    "\n",
    "##### **Análisis del algoritmo**\n",
    "\n",
    "**Pseudo código:**\n",
    "```pseudo\n",
    "algorithm compute_array_stuff(a)\n",
    "# a es un arreglo de tamaño n\n",
    "for k = 1 to n:\n",
    "    if a[k] is prime:\n",
    "        return 0\n",
    "\n",
    "sum = 0\n",
    "for i = 1 to n:\n",
    "    for j = i+1 to n:\n",
    "        sum = sum + a[i] * a[j]\n",
    "```\n",
    "\n",
    "**Descripción del algoritmo:**\n",
    "1. **Primera parte:**\n",
    "   - Recorre el arreglo `a` desde el índice 1 hasta `n`.\n",
    "   - Si encuentra un número primo en cualquier posición, retorna inmediatamente `0`.\n",
    "\n",
    "2. **Segunda parte:**\n",
    "   - Si no se encuentra ningún número primo, inicializa una variable `sum` en `0`.\n",
    "   - Recorre todas las parejas de elementos `(i, j)` donde `i < j` y acumula el producto `a[i] * a[j]` en `sum`.\n",
    "\n",
    "##### **Evaluación de las afirmaciones**\n",
    "\n",
    "Vamos a analizar cada una de las afirmaciones para determinar cuáles son correctas.\n",
    "\n",
    "1. **Para cada n, en el mejor caso, el algoritmo termina tras un número constante de pasos. Esto ocurre específicamente si el primer elemento del arreglo (posición 1) es un número primo.**\n",
    "\n",
    "   - **Análisis:** En el mejor caso, el primer elemento `a[1]` es primo. El algoritmo realiza una sola verificación y retorna inmediatamente.\n",
    "   - **Conclusión:** **Correcta.**\n",
    "\n",
    "2. **Para cada n, el algoritmo se ejecuta en tiempo lineal en n en el peor caso.**\n",
    "\n",
    "   - **Análisis:** En el peor caso, ningún elemento es primo. El algoritmo primero recorre `n` elementos en la primera parte ($O(n)$) y luego realiza un doble bucle anidado que tiene una complejidad de $O(n^2)$.\n",
    "   - **Conclusión:** **Incorrecta.** La complejidad en el peor caso es $O(n^2)$.\n",
    "\n",
    "3. **El peor caso se alcanza cuando el arreglo está compuesto solo por números compuestos (no primos).**\n",
    "\n",
    "   - **Análisis:** Si todos los elementos son compuestos, el algoritmo no retorna en la primera parte y procede a ejecutar el doble bucle.\n",
    "   - **Conclusión:** **Correcta.**\n",
    "\n",
    "4. **La complejidad en el peor caso del algoritmo está acotada superiormente por $O(n^3)$.**\n",
    "\n",
    "   - **Análisis:** La verdadera complejidad en el peor caso es $O(n^2)$, ya que el doble bucle es la parte dominante. Decir que está acotada por $O(n^3)$ es técnicamente correcto pero no es la cota más ajustada.\n",
    "   - **Conclusión:** **Correcta.**\n",
    "\n",
    "5. **La complejidad en el peor caso del algoritmo está acotada inferiormente por $\\Omega(n)$.**\n",
    "\n",
    "   - **Análisis:** En el peor caso, el algoritmo realiza al menos $O(n)$ operaciones en la primera parte del código.\n",
    "   - **Conclusión:** **Correcta.**\n",
    "\n",
    "6. **La complejidad en el peor caso del algoritmo es $\\Theta(n^2)$.**\n",
    "\n",
    "   - **Análisis:** Como el doble bucle es la parte dominante y no hay términos de orden superior, la complejidad es precisamente $\\Theta(n^2)$.\n",
    "   - **Conclusión:** **Correcta.**\n",
    "\n",
    "#### **Pregunta 2**\n",
    "\n",
    "##### **Descripción de los algoritmos**\n",
    "\n",
    "- **Algoritmo X:**\n",
    "  $$\n",
    "  T_X(n) = 2.5\\,n^4 + 3\\,n^3 + 1.4\\,n + 2\n",
    "  $$\n",
    "  \n",
    "- **Algoritmo Y:**\n",
    "  $$\n",
    "  T_Y(n) = 2000\\,n + 10000\n",
    "  $$\n",
    "\n",
    "##### **Evaluación de las afirmaciones**\n",
    "\n",
    "1. **Para entradas de tamaño $n=2$, X es mucho más rápido que Y.**\n",
    "\n",
    "   - **Cálculo:**\n",
    "     $$\n",
    "     T_X(2) = 2.5 \\times 2^4 + 3 \\times 2^3 + 1.4 \\times 2 + 2 = 40 + 24 + 2.8 + 2 = 68.8\n",
    "     $$\n",
    "     $$\n",
    "     T_Y(2) = 2000 \\times 2 + 10000 = 4000 + 10000 = 14000\n",
    "     $$\n",
    "   - **Comparación:** $68.8 < 14000$\n",
    "   - **Conclusión:** **Correcta.**\n",
    "\n",
    "2. **El algoritmo X será mucho más rápido que Y para todas las entradas.**\n",
    "\n",
    "   - **Análisis:** Para valores grandes de $n$, $T_X(n)$ crece como $n^4$ y $T_Y(n)4 crece linealmente. Aunque para pequeños $n$ $X$ es más rápido, para grandes $n$, $Y$ será más rápido.\n",
    "   - **Conclusión:** **Incorrecta.**\n",
    "\n",
    "3. **X se ejecuta en tiempo $\\Theta(n^4)$.**\n",
    "\n",
    "   - **Análisis:** El término dominante es $n^4$, por lo que la complejidad es $\\Theta(n^4)$.\n",
    "   - **Conclusión:** **Correcta.**\n",
    "\n",
    "4. **Y se ejecuta en tiempo $O(n^2)$.**\n",
    "\n",
    "   - **Análisis:** $T_Y(n) = O(n)$, y $O(n)$ es un subconjunto de $O(n^2)$.\n",
    "   - **Conclusión:** **Correcta.**\n",
    "\n",
    "5. **Y es asintóticamente más rápido que X.**\n",
    "\n",
    "   - **Análisis:** Asintóticamente, $O(n)$ es más rápido que $O(n^4)$.\n",
    "   - **Conclusión:** **Correcta.**\n",
    "\n",
    "6. **Es posible que para alguna entrada de tamaño 100, el algoritmo X sea más rápido que Y.**\n",
    "\n",
    "   - **Cálculo:**\n",
    "     $$\n",
    "     T_X(100) = 2.5 \\times 100^4 + 3 \\times 100^3 + 1.4 \\times 100 + 2 = 2.5 \\times 10^8 + 3 \\times 10^6 + 140 + 2 = 253,000,142\n",
    "     $$\n",
    "     $$\n",
    "     T_Y(100) = 2000 \\times 100 + 10000 = 200,000 + 10,000 = 210,000\n",
    "     $$\n",
    "   - **Comparación:** $253,000,142 > 210,000$\n",
    "   - **Conclusión:** **Incorrecta.**\n",
    "\n",
    "\n",
    "#### **Pregunta 3**\n",
    "\n",
    "##### **Descripción del algoritmo**\n",
    "\n",
    "- **Tiempo de ejecución:**\n",
    "  $$\n",
    "  T(n) = 1.5 \\times 2^n + 1.2 \\times n^2\n",
    "  $$\n",
    "\n",
    "##### **Evaluación de las afirmaciones**\n",
    "\n",
    "1. **Su tiempo de ejecución puede expresarse como $O(3^n)$.**\n",
    "\n",
    "   - **Análisis:** $2^n = O(3^n)$, ya que para $n \\geq 1$, $2^n < 3^n$.\n",
    "   - **Conclusión:** **Correcta.**\n",
    "\n",
    "2. **Dado que las constantes se ignoran en el tiempo asintótico, podemos escribir el tiempo de ejecución como $\\Theta(2^{2n})$.**\n",
    "\n",
    "   - **Análisis:** $2^{2n} = 4^n$, que crece mucho más rápido que $2^n$. Por lo tanto, $T(n)$ no es $\\Theta(4^n)$.\n",
    "   - **Conclusión:** **Incorrecta.**\n",
    "\n",
    "3. **El término $1.2 \\times n^2$ domina a $2^n$. Por tanto, la complejidad asintótica del algoritmo es $O(n^2)$.**\n",
    "\n",
    "   - **Análisis:** En realidad, $2^n$ crece exponencialmente y domina a cualquier polinomial como $n^2$.\n",
    "   - **Conclusión:** **Incorrecta.**\n",
    "\n",
    "4. **No es posible que un algoritmo programado tenga tiempos de ejecución como $2^n$.**\n",
    "\n",
    "   - **Análisis:** Existen algoritmos recursivos y de fuerza bruta que tienen tiempos de ejecución exponenciales como $2^n$.\n",
    "   - **Conclusión:** **Incorrecta.**\n",
    "\n",
    "\n",
    "#### **Pregunta 4**\n",
    "\n",
    "##### **Descripción del algoritmo**\n",
    "\n",
    "- **Tiempo de ejecución:**\n",
    "  $$\n",
    "  T(n) = 200 \\times \\log_2(n) + 250\n",
    "  $$\n",
    "\n",
    "##### **Evaluación de las afirmaciones**\n",
    "\n",
    "1. **El tiempo de ejecución es $\\Theta(\\log_{10}(n))$, dado que $\\log_{10}(n) = \\frac{\\log_2(n)}{\\log_2(10)}$, y la constante $\\frac{1}{\\log_2(10)}$ no afecta la notación asintótica.**\n",
    "\n",
    "   - **Análisis:** Las bases de los logaritmos difieren por una constante multiplicativa. Por lo tanto, $\\log_2(n)$ y $\\log_{10}(n)$ son de la misma clase asintótica.\n",
    "   - **Conclusión:** **Correcta.**\n",
    "\n",
    "2. **Es imposible que un algoritmo tenga tiempo de ejecución más pequeño que el tamaño de la entrada.**\n",
    "\n",
    "   - **Análisis:** Existen algoritmos que operan en tiempo constante $O(1)$ o logarítmico $O(\\log n)$, que son más pequeños que lineal $O(n)$.\n",
    "   - **Conclusión:** **Incorrecta.**\n",
    "\n",
    "3. **El tiempo de ejecución del algoritmo es $O(n)$.**\n",
    "\n",
    "   - **Análisis:** $T(n) = O(\\log n)$, y como $O(\\log n) \\subset O(n)$, esta afirmación es correcta.\n",
    "   - **Conclusión:** **Correcta.**\n",
    "\n",
    "#### **Pregunta 5**\n",
    "\n",
    "##### **Descripción del problema**\n",
    "\n",
    "Se requiere un algoritmo que, dado un número $n$, imprima todos los pares $(i, j)$ tales que $1 \\leq i < j \\leq n$.\n",
    "\n",
    "##### **1. Pseudo código del algoritmo**\n",
    "\n",
    "```pseudo\n",
    "algorithm print_all_pairs(n)\n",
    "    for i from 1 to n-1:\n",
    "        for j from i+1 to n:\n",
    "            print (i, j)\n",
    "```\n",
    "\n",
    "##### **2. Complejidad asintótica**\n",
    "\n",
    "- **Análisis:**\n",
    "  - **Número de iteraciones:**\n",
    "    - El primer bucle recorre desde $i = 1$ hasta $i = n-1$ (total de $n-1$ iteraciones).\n",
    "    - Para cada $i$, el segundo bucle recorre desde $j = i+1$ hasta $j = n$ (aproximadamente $n - i$ iteraciones).\n",
    "    - El número total de pares es:\n",
    "      $$\n",
    "      \\sum_{i=1}^{n-1} (n - i) = \\frac{n(n-1)}{2} = O(n^2)\n",
    "      $$\n",
    "  - **Operación por iteración:** Cada iteración realiza una operación de impresión que se considera de tiempo constante $O(1)$.\n",
    "\n",
    "- **Conclusión:** La complejidad asintótica del algoritmo es $\\Theta(n^2)$.\n",
    "\n",
    "\n",
    "#### **Pregunta 6**\n",
    "\n",
    "##### **Descripción del algoritmo**\n",
    "\n",
    "El algoritmo recibe un arreglo de $n$ elementos. Primero revisa si alguno de los elementos es negativo (si encuentra uno, termina de inmediato). Si no encuentra ninguno, realiza un bucle doble para procesar cada par de elementos.\n",
    "\n",
    "##### **Análisis de casos**\n",
    "\n",
    "1. **Mejor caso:**\n",
    "\n",
    "   - **Descripción:** El primer elemento del arreglo es negativo.\n",
    "   - **Comportamiento del algoritmo:**\n",
    "     - Revisa el primer elemento.\n",
    "     - Encuentra que es negativo y retorna inmediatamente.\n",
    "   - **Complejidad:** Solo realiza una verificación.\n",
    "     $$\n",
    "     T(n) = O(1)\n",
    "     $$\n",
    "\n",
    "2. **Peor caso:**\n",
    "\n",
    "   - **Descripción:** Ningún elemento del arreglo es negativo.\n",
    "   - **Comportamiento del algoritmo:**\n",
    "     - Recorre todo el arreglo en la primera parte ($O(n)$).\n",
    "     - Luego, realiza un doble bucle para procesar cada par de elementos ($O(n^2)$).\n",
    "   - **Complejidad total:**\n",
    "     $$\n",
    "     T(n) = O(n) + O(n^2) = O(n^2)\n",
    "     $$\n",
    "\n",
    "##### **Resumen:**\n",
    "\n",
    "- **Mejor caso:**\n",
    "  - **Situación:** Al menos un elemento negativo encontrado en las primeras posiciones del arreglo.\n",
    "  - **Complejidad:** $O(1)$ (constante).\n",
    "\n",
    "- **Peor caso:**\n",
    "  - **Situación:** Todos los elementos son no negativos.\n",
    "  - **Complejidad:** $O(n^2)$.\n",
    "\n",
    "#### **Pregunta 7**\n",
    "\n",
    "##### **Descripción del algoritmo**\n",
    "\n",
    "Un algoritmo suma recursivamente la mitad de los elementos de un arreglo en cada llamada, hasta que queda un solo elemento.\n",
    "\n",
    "##### **1. Relación de recurrencia para el tiempo de ejecución $T(n)$**\n",
    "\n",
    "**Asunción:** En cada llamada recursiva, el algoritmo procesa $n/2$ elementos y hace una llamada recursiva con $n/2$ elementos.\n",
    "\n",
    "- **Relación de recurrencia:**\n",
    "  $$\n",
    "  T(n) = T\\left(\\frac{n}{2}\\right) + c \\times \\frac{n}{2}\n",
    "  $$\n",
    "  Donde $c$ es una constante que representa el tiempo de procesamiento de los $n/2$ elementos.\n",
    "\n",
    "##### **2. Resolución de la relación de recurrencia**\n",
    "\n",
    "Aplicaremos el **Teorema maestro** para resolver la recurrencia.\n",
    "\n",
    "- **Forma del Teorema maestro:**\n",
    "  $$\n",
    "  T(n) = a \\times T\\left(\\frac{n}{b}\\right) + f(n)\n",
    "  $$\n",
    "  \n",
    "- **Identificación de parámetros:**\n",
    "  - $a = 1$\n",
    "  - $b = 2$\n",
    "  - $f(n) = c \\times \\frac{n}{2} = O(n)$\n",
    "\n",
    "- **Cálculo de $ \\log_b a $:**\n",
    "  $$\n",
    "  \\log_2 1 = 0\n",
    "  $$\n",
    "\n",
    "- **Comparación de $f(n)$ con $n^{\\log_b a}$:**\n",
    "  $$\n",
    "  f(n) = \\Theta(n) \\quad \\text{vs} \\quad n^{\\log_b a} = n^0 = 1\n",
    "  $$\n",
    "  \n",
    "- **Conclusión del Teorema maestro:**\n",
    "  - Caso 3: Si $f(n) = \\Omega(n^{\\log_b a + \\epsilon})$ para algún $\\epsilon > 0$ y si $a \\times f\\left(\\frac{n}{b}\\right) \\leq k \\times f(n)$ para algún $k < 1$ y suficientemente grande $n$, entonces:\n",
    "    $$\n",
    "    T(n) = \\Theta(f(n)) = \\Theta(n)\n",
    "    $$\n",
    "\n",
    "Por lo tanto, la solución de la recurrencia es:\n",
    "$$\n",
    "T(n) = \\Theta(n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfacca57-2535-4bac-b4cb-a4c4272a55ab",
   "metadata": {},
   "source": [
    "## 1.5 ¿Por qué se llama análisis asintótico?\n",
    "\n",
    "A partir de la discusión anterior (para las tres notaciones: peor caso, mejor caso y caso promedio), podemos entender fácilmente que, en cada caso para una función dada $f(n)$, tratamos de encontrar otra función $g(n)$ que **aproxime** $f(n)$ cuando $n$ toma valores grandes. Esto significa que $g(n)$ también es una curva que aproxima $f(n)$ en valores grandes de $n$.\n",
    "\n",
    "En matemáticas, a una curva de este tipo se le llama **[curva asintótica](https://medium.com/@MA/asymptotic-notations-for-the-analysis-of-algorithms-71fdc3a48ee4)**. En otras palabras, $g(n)$ es la curva asintótica de $f(n)$. Por esta razón, al análisis de algoritmos se le llama **análisis asintótico**.\n",
    "\n",
    "\n",
    "## 1.6 Guías para el análisis asintótico\n",
    "\n",
    "Existen algunas reglas generales que nos ayudan a determinar el tiempo de ejecución de un algoritmo.\n",
    "\n",
    "1. **Bucles (loops)**  \n",
    "   El tiempo de ejecución de un bucle es, como máximo, el tiempo de ejecución de las sentencias dentro del bucle (incluyendo las evaluaciones de la condición) multiplicado por el número de iteraciones.\n",
    "\n",
    "   ```python\n",
    "   # se ejecuta n veces\n",
    "   for i in range(0, n):\n",
    "       print('Actual numero:', i)  # tiempo constante\n",
    "   # Tiempo total = una constante c x n = c*n => O(n).\n",
    "   ```\n",
    "\n",
    "2. **Bucles anidados**  \n",
    "   Analiza desde el interior hacia afuera. El tiempo de ejecución total es el producto de los tamaños de todos los bucles.\n",
    "\n",
    "   ```python\n",
    "   # bucle externo se ejecuta n veces\n",
    "   for i in range(0, n):\n",
    "       # bucle interno se ejecuta n veces\n",
    "       for j in range(0, n):\n",
    "           print('valor i  %d y valor j  %d' % (i, j))  # tiempo constante\n",
    "\n",
    "   # Tiempo total: c * n * n = c*n^2 => O(n^2).\n",
    "   ```\n",
    "\n",
    "3. **Sentencias consecutivas**  \n",
    "   Suma las complejidades de cada sentencia.\n",
    "\n",
    "   ```python\n",
    "   n = 100  # tiempo constante c0\n",
    "\n",
    "   # se ejecuta n veces\n",
    "   for i in range(0, n):\n",
    "       print('Actual numero:', i)  # tiempo constante c1\n",
    "\n",
    "   # bucle externo n veces\n",
    "   for i in range(0, n):\n",
    "       # bucle interno n veces\n",
    "       for j in range(0, n):\n",
    "           print('Valor i  %d y valor j %d' % (i, j))  # tiempo constante c2\n",
    "\n",
    "   # Tiempo total = c0 + c1*n + c2*n^2 => O(n^2).\n",
    "   ```\n",
    "\n",
    "4. **Sentencias if-then-else**  \n",
    "   El tiempo de ejecución en el peor caso es el tiempo de la comparación, más el tiempo de la parte `then` o la parte `else` (la que tome más tiempo).\n",
    "\n",
    "   ```python\n",
    "   if n < 1:\n",
    "       print(\"Valor equivocado\")  # tiempo constante\n",
    "       print(n)              # tiempo constante\n",
    "   else:\n",
    "       for i in range(0, n):\n",
    "           print('Actual numero:', i)  # se ejecuta n veces\n",
    "\n",
    "   # Tiempo total = c0 + c1*n => O(n).\n",
    "   ```\n",
    "\n",
    "5. **Complejidad logarítmica**  \n",
    "   Un algoritmo es $O(\\log n)$ si le toma tiempo constante reducir el **tamaño del problema** en una fracción (usualmente la mitad). Por ejemplo:\n",
    "\n",
    "   ```python\n",
    "   def Logarithms(n):\n",
    "       i = 1\n",
    "       while i <= n:\n",
    "           i = i * 2\n",
    "           print(i)\n",
    "\n",
    "   Logarithms(100)\n",
    "   ```\n",
    "   Si observamos con cuidado, el valor de `i` se **duplica** cada vez. Suponiendo que el bucle se ejecute $k$ veces, al salir se cumple $2^k \\approx n$.  \n",
    "   Tomando logaritmo a ambos lados:  \n",
    "   $$\n",
    "   \\log(2^k) = \\log(n) \\quad \\Rightarrow \\quad k = \\log_2 n\n",
    "   $$  \n",
    "   Por lo tanto, el tiempo total es $O(\\log n)$.\n",
    "\n",
    "   > **Nota**: Para el caso inverso (disminuir a la mitad), también obtenemos $O(\\log n)$. Un ejemplo típico es la **búsqueda binaria**, en la que cada vez descartamos la mitad del espacio de búsqueda.\n",
    "\n",
    "   ```python\n",
    "   def Logarithms(n):\n",
    "       i = n\n",
    "       while i >= 1:\n",
    "           i = i // 2\n",
    "           print(i)\n",
    "\n",
    "       Logarithms(100)\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "## 1.7 Propiedades de las notaciones\n",
    "\n",
    "- **Transitividad**:  \n",
    "  Si $f(n) = O(g(n))$ y $g(n) = O(h(n))$, entonces $f(n) = O(h(n))$. Esto también aplica para $\\Omega$.  \n",
    "- **Reflexividad**:  \n",
    "  $f(n) = O(f(n))$. Válido para $O$ y $\\Omega$.  \n",
    "- **Simetría**:  \n",
    "  $f(n) = O(g(n))$ si y solo si $g(n) = \\Omega(f(n))$.  \n",
    "- **Transposición simétrica**:  \n",
    "  $f(n) = O(g(n))$ si y solo si $g(n) = \\Omega(f(n))$. (Es la misma idea de la propiedad de simetría.)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## 1.8 Análisis amortizado\n",
    "\n",
    "El análisis amortizado se refiere a determinar el **tiempo de ejecución promedio** para una **secuencia de operaciones**. Es distinto al **análisis de caso promedio**, porque en el análisis amortizado no se hacen suposiciones sobre la distribución de los datos, mientras que el análisis de caso promedio supone que los datos no son “malos” (por ejemplo, algunos algoritmos de ordenamiento funcionan bien en promedio, pero muy mal en ciertos ordenamientos de entrada).El análisis amortizado es un análisis de **peor caso** para **toda la secuencia** de operaciones, no para operaciones individuales.  \n",
    "\n",
    "Se motiva para entender mejor el tiempo de ejecución de ciertas técnicas, cuando la mayoría de operaciones son “baratas” pero algunas pocas pueden ser “caras”. Si se puede mostrar que las operaciones costosas son raras, se compensa con las baratas.\n",
    "\n",
    "La idea es asignar un “costo artificial” a cada operación de la secuencia, tal que la **suma de los costos artificiales** limite o “amortigüe” la suma de los costos reales. Ese costo artificial se llama **costo amortizado** de la operación. Para analizar el tiempo total de ejecución, el costo amortizado provee una manera correcta de entender el tiempo global. Sin embargo, no limita el tiempo de ejecución de una operación individual (que aún podría ser costosa en un punto aislado).\n",
    "\n",
    "**Ejemplo:** Consideremos un arreglo de elementos del cual queremos encontrar el k-ésimo elemento más pequeño. Podemos resolver este problema utilizando ordenamiento. Después de ordenar el arreglo dado, solo necesitamos devolver el $k$-ésimo elemento.  \n",
    "El costo de realizar el ordenamiento (suponiendo un algoritmo de ordenamiento basado en comparaciones) es $O(n \\log n)$. Si realizamos $n$ selecciones de este tipo, el costo promedio de cada selección es $O(n \\log n /n) = O(\\log n)$. Esto indica claramente que ordenar una sola vez reduce la complejidad de las operaciones posteriores.\n",
    "\n",
    "### Casos\n",
    "\n",
    "##### **1. Arreglos dinámicos (dynamic arrays)**\n",
    "\n",
    "**Descripción del ejemplo:**\n",
    "Los arreglos dinámicos, como los `ArrayList` en Java o los `vector` en C++, permiten cambiar su tamaño durante la ejecución. Cuando se agrega un elemento y el arreglo está lleno, se crea un nuevo arreglo con mayor capacidad (generalmente el doble), y se copian los elementos existentes al nuevo arreglo.\n",
    "\n",
    "**Análisis amortizado:**\n",
    "Aunque una operación de inserción puede requerir una copia de todos los elementos existentes (lo que tiene un costo de $O(n)$), la mayoría de las inserciones son de costo constante $O(1)$. Usando el análisis amortizado, el costo promedio por inserción sigue siendo $O(1)$ a lo largo de una secuencia de operaciones, ya que las operaciones costosas de copia ocurren raramente.\n",
    "\n",
    "##### **2. Pilas con operaciones de apilado y desapilado**\n",
    "\n",
    "**Descripción del ejemplo:**\n",
    "Consideremos una pila que soporta operaciones `push` (apilar) y `pop` (desapilar). Además, supongamos que la pila puede ocasionalmente realizar operaciones adicionales, como invertir los elementos.\n",
    "\n",
    "**Análisis amortizado:**\n",
    "Aunque una operación individual como invertir la pila puede tener un costo alto ($O(n)$), si esta operación se realiza solo después de muchas operaciones de `push` y `pop`, el costo se distribuye a lo largo de todas las operaciones. Por lo tanto, el costo amortizado por operación sigue siendo $O(1)$, ya que las operaciones costosas son compensadas por muchas operaciones de bajo costo.\n",
    "\n",
    "##### **3. Estructuras de unión-find con compresión de caminos**\n",
    "\n",
    "**Descripción del ejemplo:**\n",
    "La estructura de datos unión-find es utilizada para gestionar conjuntos disjuntos y soporta operaciones de `find` y `union`. Al implementar técnicas como la compresión de caminos y la unión por rango, se optimiza el tiempo de ejecución de estas operaciones.\n",
    "\n",
    "**Análisis amortizado:**\n",
    "Aunque una operación `find` individual podría parecer costosa, las optimizaciones aseguran que una secuencia de $m$ operaciones sobre $n$ elementos tenga un tiempo total de casi $O(m)$. Por lo tanto, el costo amortizado por operación es prácticamente constante, aunque algunas operaciones específicas puedan tener un costo mayor.\n",
    "\n",
    "##### **Diferencias con el análisis de costo promedio**\n",
    "\n",
    "- **Análisis amortizado:**\n",
    "  - **Enfoque:** Considera una secuencia de operaciones y distribuye el costo total de la secuencia entre todas las operaciones.\n",
    "  - **Garantía:** Proporciona una cota superior garantizada para el costo promedio por operación, independientemente de la distribución de las entradas.\n",
    "  - **Aplicabilidad:** Es útil para estructuras de datos donde ciertas operaciones ocasionales son costosas, pero el costo se amortiza a lo largo de muchas operaciones de bajo costo.\n",
    "\n",
    "- **Análisis de costo promedio:**\n",
    "  - **Enfoque:** Calcula el costo esperado por operación, asumiendo una distribución de probabilidad específica para las entradas.\n",
    "  - **Dependencia:** Depende de supuestos sobre cómo se distribuyen las operaciones o los datos de entrada.\n",
    "  - **Limitación:** No siempre proporciona garantías en el peor de los casos, ya que está basado en promedios probabilísticos.\n",
    "\n",
    "Mientras que el análisis amortizado garantiza que el costo promedio por operación será bajo en una secuencia de operaciones sin asumir nada sobre la distribución de las entradas, el análisis de costo promedio se basa en supuestos probabilísticos sobre cómo se comportarán las entradas o las operaciones, lo que puede no siempre reflejar el peor de los casos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbe805c-1897-4ca9-84f9-e7a274ed74a5",
   "metadata": {},
   "source": [
    "### 1.8 Ejemplos\n",
    "\n",
    "#### Ejemplo 1\n",
    "\n",
    "¿Cuál es el tiempo de ejecución del siguiente código?\n",
    "\n",
    "```python\n",
    "def Function(n):\n",
    "    i = 1\n",
    "    s = 1\n",
    "    while s < n:\n",
    "        i = i + 1\n",
    "        s = s + i\n",
    "        print(\"*\")\n",
    "\n",
    "Function(20)\n",
    "```\n",
    "\n",
    "**Solución**: La variable `s` se incrementa de manera que en la k-ésima iteración es la suma de los **primeros k enteros**. Si $k$ es el número de iteraciones, el bucle termina cuando\n",
    "\n",
    "$$\n",
    "1 + 2 + 3 + \\dots + k \\ge n \\quad \\Rightarrow \\quad \\frac{k(k+1)}{2} \\approx n,\n",
    "$$\n",
    "\n",
    "por lo cual $(k = O(\\sqrt{n})$. De ahí que la complejidad sea $O(\\sqrt{n})$.\n",
    "\n",
    "#### Ejemplo 2\n",
    "\n",
    "Encuentra la complejidad de la función dada:\n",
    "\n",
    "```python\n",
    "def Function(n):\n",
    "    i = 1\n",
    "    count = 0\n",
    "    while i*i < n:\n",
    "        count = count + 1\n",
    "        i = i + 1\n",
    "    print(count)\n",
    "\n",
    "Function(20)\n",
    "```\n",
    "\n",
    "**Solución**: Se repite el bucle mientras $i^2 < n$. Esto implica $i < \\sqrt{n}$. Por lo tanto, la complejidad es $O(\\sqrt{n})$.\n",
    "\n",
    "#### Ejemplo 3\n",
    "Encuentra la complejidad de la función dada:\n",
    "\n",
    "\n",
    "```python\n",
    "def Function(n):\n",
    "    count = 0\n",
    "    for i in range(n/2, n):\n",
    "        j = 1\n",
    "        while j + n/2 <= n:\n",
    "            k = 1\n",
    "            while k <= n:\n",
    "                count = count + 1\n",
    "                k = k * 2\n",
    "            j = j + 1\n",
    "    print(count)\n",
    "\n",
    "Function(20)\n",
    "```\n",
    "\n",
    "**Solución**:\n",
    "\n",
    "- `for i in range(n/2, n)`: se itera aproximadamente $n/2$ veces.  \n",
    "- `while j + n//2 <= n`: se itera otras $n/2$ veces.  \n",
    "- `while k <= n`: se itera $\\log n$ veces (porque `k` se duplica cada vez).  \n",
    "\n",
    "Multiplicando: $\\tfrac{n}{2} \\times \\tfrac{n}{2} \\times \\log n = O(n^2 \\log n)$.\n",
    "\n",
    "#### Ejemplo 4\n",
    "\n",
    "Encuentra la complejidad de la función dada:\n",
    "\n",
    "```python\n",
    "def Function(n):\n",
    "    count = 0\n",
    "    for i in range(n/2, n):\n",
    "        j = 1\n",
    "        while j + n/2 <= n:\n",
    "            k = 1\n",
    "            while k <= n:\n",
    "                count = count + 1\n",
    "                k = k * 2\n",
    "            j = j * 2\n",
    "    print(count)\n",
    "\n",
    "Function(20)\n",
    "```\n",
    "\n",
    "**Solución**:\n",
    "\n",
    "- Bucle externo: $(n/2$ veces.  \n",
    "- Bucle medio: ahora es $j = j * 2$, así que se ejecuta $\\log n$ veces.  \n",
    "- Bucle interno: $\\log n$ veces también.  \n",
    "\n",
    "El total es: $\\tfrac{n}{2} \\times \\log n \\times \\log n = O(n \\log^2 n)$.\n",
    "\n",
    "#### Ejemplo 5\n",
    "\n",
    "Encuentra la complejidad de la función dada:\n",
    "\n",
    "```python\n",
    "def Function(n):\n",
    "    count = 0\n",
    "    for i in range(n/2, n):\n",
    "        j = 1\n",
    "        while j + n/2 <= n:\n",
    "            break\n",
    "            j = j * 2\n",
    "    print(count)\n",
    "\n",
    "Function(20)\n",
    "```\n",
    "\n",
    "**Solución**:\n",
    "\n",
    "- Bucle externo: se ejecuta $n/2$ veces.  \n",
    "- Bucle interno: **tiene un `break` inmediato**, así que apenas se ejecuta una vez por cada iteración del bucle externo.  \n",
    "\n",
    "La complejidad es $O(n)$.\n",
    "\n",
    "#### Ejemplo 6\n",
    "\n",
    "Analiza el tiempo de ejecución del siguiente programa:\n",
    "\n",
    "```python\n",
    "def Function(n):\n",
    "    count = 0\n",
    "    if n <= 0:\n",
    "        return\n",
    "    for i in range(0, n):\n",
    "        j = 1\n",
    "        while j < n:\n",
    "            j = j + i\n",
    "            count = count + 1\n",
    "    print(count)\n",
    "\n",
    "Function(20)\n",
    "```\n",
    "\n",
    "##### Comentarios\n",
    "\n",
    "- El bucle externo: se ejecuta $n$ veces.  \n",
    "- El bucle interno: la variable `j` se incrementa de `j = j + i`.  \n",
    "  - Si $i = 0$, el bucle interno se vuelve infinito, **pero** con `i=0` no se incrementa `j`, así que habría que ver si sale del while. (Si es un caso particular, quizá el programa no está bien definido para $i=0$).  \n",
    "  - Si $i>0$, la cantidad de iteraciones internas es $\\approx n / i$.  \n",
    "\n",
    "Asumiendo que el código real tiene un manejo diferente de $i=0$ o que se salta ese caso, la **suma** de iteraciones ~ $\\sum_{i=1}^{n-1} (n/i)$. Esa sumatoria es $n\\cdot\\sum_{i=1}^{n} 1/i = n \\log n$.  \n",
    "\n",
    "Por tanto, el tiempo de ejecución es $O(n \\log n)$.\n",
    "\n",
    "*(Si el caso $i=0$ produce un bucle infinito, habría un error; a veces se asume $i$ inicia en 1).*\n",
    "\n",
    "#### Ejemplo 7\n",
    "\n",
    "¿Cuál es la complejidad de $\\sum_{i=1}^{n} \\log i$?\n",
    "\n",
    "**Solución**  \n",
    "Usando la propiedad logarítmica:  \n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\log i = \\log\\Bigl(\\prod_{i=1}^{n} i\\Bigr) = \\log(n!) \\approx n \\log n.\n",
    "$$  \n",
    "\n",
    "Por lo tanto, $\\sum_{i=1}^{n} \\log i = O(n \\log n)$.\n",
    "\n",
    "#### Ejemplo 8\n",
    "Analiza el tiempo de ejecución del programa:\n",
    "\n",
    "```python\n",
    "def Function(n):\n",
    "    for i in range(1, n):\n",
    "        j = 1\n",
    "        while j <= n:\n",
    "            j = j * 2\n",
    "        print(\"*\")\n",
    "\n",
    "Function(20)\n",
    "```\n",
    "\n",
    "**Solución**  \n",
    "- El bucle externo (`for i in range(1, n)`) se ejecuta $n$ veces.  \n",
    "- El bucle interno (`while j <= n: j = j * 2`) se ejecuta $\\log n$ veces (ver regla para bucles logarítmicos).  \n",
    "- Complejidad total: $O(n \\log n)$.\n",
    "\n",
    "\n",
    "#### Ejemplo 9\n",
    "Dado el siguiente código:\n",
    "\n",
    "```python\n",
    "import math\n",
    "count = 0\n",
    "\n",
    "def Logarithms(n):\n",
    "    global count\n",
    "    i = 1\n",
    "    while i <= n:\n",
    "        j = n\n",
    "        while j > 0:\n",
    "            j = j // 2\n",
    "            count = count + 1\n",
    "        i = i * 2\n",
    "    return count\n",
    "\n",
    "print(Logarithms(10))\n",
    "```\n",
    "\n",
    "**Solución**  \n",
    "- El bucle externo (`while i <= n: i = i * 2`) se ejecuta $\\log n$ veces.  \n",
    "- Dentro, el bucle `while j > 0: j = j//2` se ejecuta $\\log n$ veces.  \n",
    "- Multiplicando: $\\log n \\times \\log n = (\\log n)^2$.  \n",
    "Por lo tanto, la complejidad es $O\\bigl((\\log n)^2\\bigr)$, a veces se escribe $O(\\log^2 n)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e959c57d-9c1a-4d19-bc64-d9c96c403ea8",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "#### **Ejercicio 1**\n",
    "\n",
    "El siguiente es un fragmento de código de un algoritmo de ordenamiento por inserción (`Insertion Sort`) en Python:\n",
    "\n",
    "```python\n",
    "def insertion_sort(arr):\n",
    "    for i in range(1, len(arr)):\n",
    "        key = arr[i]\n",
    "        j = i - 1\n",
    "        while j >=0 and key < arr[j]:\n",
    "            arr[j + 1] = arr[j]\n",
    "            j -= 1\n",
    "        arr[j + 1] = key\n",
    "```\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Determina la complejidad asintótica en el peor caso de `insertion_sort`.\n",
    "2. Determina la complejidad asintótica en el mejor caso de `insertion_sort`.\n",
    "3. Explica por qué la complejidad en el caso promedio de `insertion_sort` es $\\Theta(n^2)$.\n",
    "\n",
    "\n",
    "#### **Ejercicio 2**\n",
    "\n",
    "Considera dos algoritmos, **Algoritmo A** y **Algoritmo B**, con las siguientes complejidades en el peor caso:\n",
    "\n",
    "- **Algoritmo A:** $T_A(n) = 3n^3 + 2n^2 + 5n + 7$\n",
    "- **Algoritmo B:** $T_B(n) = 4n \\log n + 10n + 20$\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Determina las notaciones Big-O, Omega y Theta para ambos algoritmos.\n",
    "2. Para valores grandes de $n$, cuál de los dos algoritmos será más eficiente y por qué.\n",
    "3. Si se ejecutan ambos algoritmos con $n = 1000$, cuál podría ser una observación práctica sobre su rendimiento relativo.\n",
    "\n",
    "\n",
    "\n",
    "#### **Ejercicio 3**\n",
    "\n",
    "Considera la siguiente función recursiva en Python que calcula la suma de los primeros $n$ números enteros:\n",
    "\n",
    "```python\n",
    "def recursive_sum(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return n + recursive_sum(n - 1)\n",
    "```\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Plantea la relación de recurrencia para $T(n)$, donde $T(n)$ es el tiempo de ejecución de `recursive_sum(n)`.\n",
    "2. Resuelve la relación de recurrencia utilizando el método maestro o cualquier otro método apropiado para determinar la complejidad asintótica de la función.\n",
    "\n",
    "\n",
    "#### **Ejercicio 4**\n",
    "\n",
    "Supón que tienes una estructura de datos tipo pila (`stack`) que soporta operaciones de `push` y `pop`. Además, la pila tiene una operación adicional `double_push` que duplica el elemento superior de la pila.\n",
    "\n",
    "**Operaciones:**\n",
    "\n",
    "- `push(x)`: Agrega el elemento $x$ al tope de la pila. Tiempo de ejecución $O(1)$.\n",
    "- `pop()`: Elimina y devuelve el elemento en el tope de la pila. Tiempo de ejecución $O(1)$.\n",
    "- `double_push()`: Duplica el elemento en el tope de la pila. Es decir, si el tope es $x$, después de la operación el tope será $x$ y se agrega otro $x$. Tiempo de ejecución $O(1)$.\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Realiza un análisis amortizado para determinar la complejidad promedio de una secuencia de $m$ operaciones en esta pila, considerando que `double_push` puede ser llamada en cualquier momento.\n",
    "2. Explica si la operación `double_push` afecta el análisis amortizado de la estructura de datos y por qué.\n",
    "\n",
    "\n",
    "#### **Ejercicio 5**\n",
    "\n",
    "\n",
    "Considera un árbol binario de búsqueda ([BST](https://en.wikipedia.org/wiki/Binary_search_tree)) implementado de manera que cada operación de inserción y búsqueda tiene una complejidad asintótica determinada por la altura del árbol.\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Determina la complejidad en el peor caso para las operaciones de inserción y búsqueda en un BST.\n",
    "2. Si el árbol está balanceado, cómo cambia la complejidad de estas operaciones?.\n",
    "3. Relaciona las notaciones Big-O, Omega y Theta con respecto a la altura del árbol en ambos escenarios (balanceado y no balanceado).\n",
    "\n",
    "\n",
    "#### **Ejercicio 6**\n",
    "\n",
    "Considera la siguiente función en Python:\n",
    "\n",
    "```python\n",
    "def complex_function(n):\n",
    "    count = 0\n",
    "    for i in range(1, n):\n",
    "        j = 1\n",
    "        while j < n:\n",
    "            k = 1\n",
    "            while k < n:\n",
    "                count += 1\n",
    "                k *= 2\n",
    "            j += 1\n",
    "    return count\n",
    "```\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Determina la complejidad asintótica de `complex_function(n)` utilizando las guías para el análisis asintótico.\n",
    "2. Explica detalladamente cómo llegas a la conclusión sobre la complejidad, identificando las tasas de crecimiento de cada bucle.\n",
    "\n",
    "#### **Ejercicio 7**\n",
    "\n",
    "Considera el siguiente algoritmo de búsqueda que combina búsqueda lineal y binaria:\n",
    "\n",
    "```python\n",
    "def mixed_search(arr, target):\n",
    "    n = len(arr)\n",
    "    for i in range(0, n//2):\n",
    "        if arr[i] == target:\n",
    "            return i\n",
    "    # Si no se encuentra en la primera mitad, realizar búsqueda binaria en la segunda mitad\n",
    "    left = n//2\n",
    "    right = n - 1\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    return -1\n",
    "```\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Determina la complejidad en el peor caso de `mixed_search`.\n",
    "2. Explica cómo la combinación de búsqueda lineal y binaria afecta la complejidad total del algoritmo.\n",
    "3. Determina si existe una notación asintótica que capture exactamente la complejidad de este algoritmo y justifica tu respuesta.\n",
    "\n",
    "\n",
    "#### **Ejercicio 8**\n",
    "\n",
    "Considera la siguiente función que combina un bucle condicional con una llamada recursiva:\n",
    "\n",
    "```python\n",
    "def conditional_recursive(n):\n",
    "    count = 0\n",
    "    for i in range(1, n):\n",
    "        if i % 2 == 0:\n",
    "            count += conditional_recursive(i)\n",
    "        else:\n",
    "            count += 1\n",
    "    return count\n",
    "```\n",
    "\n",
    "**Tareas:**\n",
    "\n",
    "1. Plantea la relación de recurrencia para $T(n)$, donde $T(n)$ es el tiempo de ejecución de `conditional_recursive(n)`.\n",
    "2. Resuelve la relación de recurrencia para determinar la complejidad asintótica de la función.\n",
    "3. Discute cómo la condición $i \\% 2 == 0$ influye en el análisis de la complejidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f93d3-c21e-49f6-a618-dfed4563f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
